{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "init_notebook_mode(connected=True) #plotly offline\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abrir achivo em diferentes formatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrir un arhivo formato csv\n",
    "# df = pd.read_csv(filepath_or_buffer='Arffs/java_train.csv',delimiter='\\t')\n",
    "# df = pd.read_csv(filepath_or_buffer='Arffs/thre=0123451.csv', delimiter='\\t')\n",
    "\n",
    "# Abrir un archivo formato arff \n",
    "# filename = \"thre=0123451.arff\"\n",
    "# data = arff.loadarff(filename)\n",
    "# df = pd.DataFrame(data[0])\n",
    "# df.head()\n",
    "\n",
    "\n",
    "\n",
    "# train = pd.read_csv(filepath_or_buffer='Arffs/java_train.csv', delimiter='\\t')\n",
    "# test = pd.read_csv(filepath_or_buffer='Arffs/java_test.csv', delimiter='\\t')\n",
    "df = pd.read_csv(filepath_or_buffer='Arffs/java_todo.csv', delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide data into train and test\n",
    "\n",
    "After train_test_split\n",
    "\n",
    "You do that on the training set of data. But then you have to apply the same transformation to your testing set (e.g. in cross-validation), or to newly obtained examples before forecast. But you have to use the same two parameters μ and σ (values) that you used for centering the training set.\n",
    "\n",
    "These methods are used to center/feature scale the given data. It basically helps to normalize the data within a particular range\n",
    "\n",
    "For this, we use Z-score method.\n",
    "\n",
    "Z-Score\n",
    "\n",
    "We do this on the training set of data.\n",
    "\n",
    "1.Fit(): Method calculates the parameters μ and σ and saves them as internal objects.\n",
    "\n",
    "2.Transform(): Method using these calculated parameters apply the transformation to a particular dataset.\n",
    "\n",
    "3.Fit_transform(): joins the fit() and transform() method for transformation of dataset.\n",
    "\n",
    "Code snippet for Feature Scaling/Standardisation(after train_test_split).\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit_tranform(X_train)\n",
    "sc.tranform(X_test)\n",
    "We apply the same(training set same two parameters μ and σ (values)) parameter transformation on our testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# X = pcadf.iloc[:, 0:35]\n",
    "# y = pcadf['class']\n",
    "X_todo = df.iloc[:, 0:35]\n",
    "y_todo = df[['paciente','name_class','class']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_todo, y_todo, random_state=0)\n",
    "\n",
    "\n",
    "# print(y) \n",
    "#You do that on the training set of data. But then you have to apply the same transformation to your testing set (e.g. in cross-validation), or to newly obtained examples before forecast. But you have to use the same two parameters μ and σ (values) that you used for centering the training set.\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test) \n",
    "X_todo = MinMaxScaler().fit_transform(X_todo) \n",
    "print(type(X_train)) #<class 'numpy.ndarray'>\n",
    "print(type(X_test)) #<class 'numpy.ndarray'>\n",
    "print(type(y_train)) #<class 'pandas.core.frame.DataFrame'>\n",
    "print(type(y_test)) #<class 'pandas.core.frame.DataFrame'>\n",
    "# print(X_train.shape)#(157, 35)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df.iloc[:, 0:35].values #\n",
    "# column = ['PCA'+str(i) for i in range(1,36)]\n",
    "# y= df.loc[:,['class']].values\n",
    "# x = StandardScaler().fit_transform(x)\n",
    "\n",
    "\n",
    "# pca = PCA(n_components=35)\n",
    "# principalComponents = pca.fit_transform(x)\n",
    "# principalDf = pd.DataFrame(data = principalComponents, columns = column)\n",
    "\n",
    "# pcadf = pd.concat([principalDf, df[['paciente']],df[['name_class']],df[['class']]], axis = 1)\n",
    "# pcadf.head()\n",
    "\n",
    "stdscaler = StandardScaler() \n",
    "\n",
    "xtrain = stdscaler.fit_transform(X_train)\n",
    "xtest = stdscaler.transform(X_test)\n",
    "xtodo = StandardScaler().fit_transform(X_todo)\n",
    "\n",
    "\n",
    "y_dftrain = pd.DataFrame(data = (y_train.iloc[:,0:3]).values, columns = ['paciente','name_class', 'class'])\n",
    "y_dftest = pd.DataFrame(data = (y_test.iloc[:,0:3]).values, columns = ['paciente','name_class', 'class'])\n",
    " \n",
    "\n",
    "pca = PCA(n_components=35)\n",
    "pca_train = pca.fit_transform(xtrain)\n",
    "pca_test = pca.transform(xtest)\n",
    "pca_todo = PCA(n_components=35).fit_transform(xtodo)\n",
    "\n",
    "colunas= ['PCA'+str(i) for i in range(1,36)]\n",
    "\n",
    "principalDf_train = pd.DataFrame(data = pca_train, columns =colunas) #(157, 35)\n",
    "principalDf_test = pd.DataFrame(data = pca_test, columns = colunas) #(157, 35)\n",
    "principalDf_todo = pd.DataFrame(data = pca_todo, columns = colunas) #(157, 35)\n",
    " \n",
    "pca_todo = pd.concat([principalDf_todo, y_todo[['paciente']],y_todo[['name_class']],y_todo[['class']]], axis = 1) \n",
    "print(pca_train.shape)#(157, 38)\n",
    "print(pca_test.shape)#(53, 38)\n",
    "print(pca_todo.shape)#(210, 38)\n",
    "pca_todo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save in diferent formats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save pca to arff\n",
    "pcadf_save = pd.concat([principalDf,df[['name_class']]], axis = 1)\n",
    "import arff \n",
    "arff.dump('pca_javabest.arff', pcadf_save.values, relation='pca_javabest', names=pcadf_save.columns)\n",
    "\n",
    "#save to csv\n",
    "# df = pd.concat([data, col1['paciente'], col2['name_class'],col3['class']], axis = 1)\n",
    "# df.to_csv('Arffs/thre=0123451.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = pca_todo.groupby('name_class')\n",
    "groups = dict(list(gb))\n",
    "group = set(pca_todo['name_class'])\n",
    "\n",
    "\n",
    "data = [go.Scatter(x=groups[g].PCA1, y=groups[g].PCA2,\n",
    "                   mode='markers', text= groups[g].name_class+\" \"+groups[g].paciente, name=g) \n",
    "        for g in group ]\n",
    "\n",
    "layout = go.Layout(title='', xaxis={'title': 'PCA1'}, yaxis={'title': 'PCA2'}, width=700,height=700)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='pca1_pca2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    " \n",
    "x = df.iloc[:, 0:35].values #\n",
    "y= df.loc[:,['class']].values\n",
    "\n",
    "X_embedded = TSNE(n_components=2).fit_transform(x)\n",
    "X_embedded.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NO- dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 0:35].values #\n",
    "y= df.loc[:,['class']].values\n",
    "x = StandardScaler().fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# X = pcadf[['PCA1', 'PCA2']]\n",
    "# y = pcadf['class']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "\n",
    "def plot_boundary(X, y, clf):\n",
    "#     X_mat = X[['PCA1','PCA2']].values\n",
    "    X_mat = X[:, (0,1)] \n",
    "    y_mat = y.values\n",
    "\n",
    "    # Create color maps\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
    "    cmap_bold  = ListedColormap(['#FF0000', '#00FF00'])\n",
    "\n",
    "    #clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    #clf = LogisticRegression()\n",
    "    clf.fit(X_mat, y_mat)\n",
    "\n",
    "    # Plot the decision boundary by assigning a color in the color map\n",
    "    # to each mesh point.\n",
    "    \n",
    "    mesh_step_size = .01  # step size in the mesh\n",
    "    plot_symbol_size = 50\n",
    "    \n",
    "    x_min, x_max = X_mat[:, 0].min() - 1, X_mat[:, 0].max() + 1\n",
    "    y_min, y_max = X_mat[:, 1].min() - 1, X_mat[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, mesh_step_size),\n",
    "                         np.arange(y_min, y_max, mesh_step_size))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "    ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "    ax.set_title('2 component PCA', fontsize = 20)\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot training points\n",
    "    plt.scatter(X_mat[:, 0], X_mat[:, 1], s=plot_symbol_size, c=y, cmap=cmap_bold, edgecolor = 'black')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    print('xmin= %f, xman=%f; ymin=%f,ymax=%f'%(xx.min(), xx.max(), yy.min(), yy.max()))\n",
    "\n",
    "    patch0 = mpatches.Patch(color='#FF0000', label='cancer')\n",
    "    patch1 = mpatches.Patch(color='#00FF00', label='normal') \n",
    "    plt.legend(handles=[patch0, patch1])\n",
    "\n",
    "        \n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.title('classification')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "# knn = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "# logreg = LogisticRegression()\n",
    "# lda = LinearDiscriminantAnalysis()\n",
    "svm = svm.LinearSVC()\n",
    "\n",
    "# plot_boundary(X_train, y_train, lda)\n",
    "\n",
    "x = pca_todo.iloc[:, 0:35]\n",
    "y = y_todo['class']\n",
    "\n",
    "plot_boundary(x.values, y,svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "ytr = y_train.loc[:,['class']].values.ravel()\n",
    "yte = y_test.loc[:,['class']].values.ravel()\n",
    "lda = LinearDiscriminantAnalysis() \n",
    "lda.fit(pca_train, y)\n",
    "print('Accuracy of LDA classifier on training set: {:.2f}'.format(lda.score(pca_train, ytr)))\n",
    "print('Accuracy of LDA classifier on test set: {:.2f}'.format(lda.score(pca_test, yte)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "scores = cross_val_score(lda,pca_todo.iloc[:, 0:35].values, y_todo.loc[:,['class']].values.ravel(), cv=10)\n",
    "print(\"\\nLDA\")\n",
    "print(\"Cross validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: %.2f +/- %.2f\"%(scores.mean(), scores.std())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred = lda.predict(pca_test)\n",
    "print(confusion_matrix(pca_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(pca_train, y_train)\n",
    "print('Accuracy of GNB classifier on training set: {:.2f}'.format(gnb.score(pca_train, y_train)))\n",
    "print('Accuracy of GNB classifier on test set: {:.2f}'.format(gnb.score(pca_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='poly')\n",
    "print(svm)\n",
    "svm.fit(pca_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'.format(svm.score(pca_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(pca_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'.format(knn.score(X_train, y_train)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "scores = cross_val_score(knn, X_todo, y, cv=10)\n",
    "print(\"\\nSupport vector machine\")\n",
    "print(\"Cross validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: %.2f +/- %.2f\"%(scores.mean(), scores.std())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(logreg, X_train, y_train, cv=10)\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(\"Cross validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: %.2f +/- %.2f\"%(scores.mean(), scores.std())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(dtree.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(dtree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(dtree, X_train, y_train, cv=10)\n",
    "print(\"\\nDecision Tree\")\n",
    "print(\"Cross validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: %.2f +/- %.2f\"%(scores.mean(), scores.std())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "# svm = svm.SVC(gamma='scale')\n",
    "svm = svm.LinearSVC()\n",
    "# svm = svm.SVC(kernel='poly')\n",
    "# svm = svm.SVR()\n",
    "svm.fit(pca_train, y_train)  \n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'.format(svm.score(pca_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(pca_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(svm, X_train, y_train, cv=10)\n",
    "print(\"\\nSupport vector machine\")\n",
    "print(\"Cross validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: %.2f +/- %.2f\"%(scores.mean(), scores.std())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
