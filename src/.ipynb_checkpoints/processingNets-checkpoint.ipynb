{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproch #1 threshold + intervaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#parameters \n",
    "#thre =np.linspace(0, 1, 11) #\n",
    "thre= [0.0, 0.1,   0.2,  0.3 ,0.4, 0.5, 0.6, 0.7, 0.8, 0.9 ]\n",
    "#thre= [0.0, 0.05, 0.1, 0.15, 0.2,0.25,  0.3,0.35 ,0.4,0.45, 0.5, 1.1]\n",
    "    \n",
    "reactions = pd.read_csv('ReactionMetabolites_list/R22_reactions.txt',sep=\"\\t\")\n",
    "metabolites= pd.read_csv('ReactionMetabolites_list/R22_metabolites.txt',sep=\"\\t\")\n",
    "#reading\n",
    "for class_label in ['normal', 'cancer']:\n",
    "    df = pd.read_csv('weightedNetworks/R22_'+class_label+'.txt',sep=\"\\t\").dropna() #remove rows with NaN #R22_normal\n",
    "    patients= df.columns.values\n",
    "    \n",
    "    #filtering by threshold\n",
    "    for i in range(0,len(thre)-1): \n",
    "        #selecting colunms \n",
    "        for col in range(2,107):#105 patients            \n",
    "            data_thre=df[(df.iloc[:,col] >= thre[i]) & (df.iloc[:,col] <thre[i+1])]\n",
    "            #writing\n",
    "            data_thre.iloc[:,[0,1]].to_csv('approaches/thre_interv/'+ class_label+'/'+patients[col]+'_th='+str(round(thre[i], 3))+'_'+str(round(thre[i+1], 3))+'.txt', sep='\\t', index=False,header=False) #, decimal=',')\n",
    "\n",
    "\n",
    "        #Filtering\n",
    "        # part1= dtemp[dtemp['NodeA'].isin(metabolites['ID'].values.tolist())] #columns on left with metabolites only\n",
    "        # part2= dtemp[dtemp['NodeA'].isin(reactions['ID'].values.tolist())] #columns on left with reactions only\n",
    "        # print(part1['NodeA'].size+part2['NodeA'].size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproch #2 threshold < than"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#parameters \n",
    "#thre =np.linspace(0, 1, 11) #\n",
    "thre= [0.1,   0.2,  0.3 ,0.4, 0.5, 0.6, 0.7, 0.8, 0.9 ]\n",
    "    \n",
    "reactions = pd.read_csv('ReactionMetabolites_list/R22_reactions.txt',sep=\"\\t\")\n",
    "metabolites= pd.read_csv('ReactionMetabolites_list/R22_metabolites.txt',sep=\"\\t\")\n",
    "#reading\n",
    "for class_label in ['normal', 'cancer']:\n",
    "    df = pd.read_csv('weightedNetworks/R22_'+class_label+'.txt',sep=\"\\t\").dropna() #remove rows with NaN #R22_normal\n",
    "    patients= df.columns.values\n",
    "    \n",
    "    #filtering by threshold\n",
    "    for i in range(0,len(thre)-1): \n",
    "        #selecting colunms \n",
    "        for col in range(2,107):#105 patients            \n",
    "            data_thre=df[(df.iloc[:,col] <thre[i])]\n",
    "            #writing\n",
    "            data_thre.iloc[:,[0,1]].to_csv('approaches/thre_lessthan/'+ class_label+'/'+patients[col]+'_th='+str(round(thre[i], 3))+'.txt', sep='\\t', index=False,header=False) #, decimal=',')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save weighted networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#parameters  \n",
    "    \n",
    "reactions = pd.read_csv('ReactionMetabolites_list/R22_reactions.txt',sep=\"\\t\")\n",
    "metabolites= pd.read_csv('ReactionMetabolites_list/R22_metabolites.txt',sep=\"\\t\")\n",
    "#reading\n",
    "for class_label in ['normal', 'cancer']:\n",
    "    df = pd.read_csv('weightedNetworks/R22_'+class_label+'.txt',sep=\"\\t\").dropna() #remove rows with NaN #R22_normal\n",
    "    patients= df.columns.values\n",
    "    \n",
    "\n",
    "    #selecting colunms \n",
    "    for col in range(2,107):#105 patients      \n",
    "        #writing\n",
    "        df.iloc[:,[0,1,col]].to_csv('approaches/weigth/'+ class_label+'/'+patients[col]+'.txt', sep='\\t', index=False,header=False) #, decimal=',')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting network measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "from functionHierarchical import hierarchical_degree\n",
    "\n",
    "def tic():\n",
    "    #Homemade version of matlab tic and toc functions\n",
    "    import time\n",
    "    global startTime_for_tictoc\n",
    "    startTime_for_tictoc = time.time()\n",
    "\n",
    "def toc():\n",
    "    import time\n",
    "    if 'startTime_for_tictoc' in globals():\n",
    "        print(\"Elapsed time is \" + str(time.time() - startTime_for_tictoc) + \" seconds.\")\n",
    "    else:\n",
    "        print(\"Toc: start time not set\")\n",
    "        \n",
    "def extract_measures(G):\n",
    "    \"\"\"Extract a vector of measurements\n",
    "    \"\"\"\n",
    "    num_nodes =  nx.number_of_nodes(G)\n",
    "    num_edges =  nx.number_of_edges(G)\n",
    "    if num_nodes == 0:\n",
    "        raise Exception('graph is empty')   \n",
    "    else: \n",
    "        F = {} #features \n",
    "\n",
    "        \"\"\" Global \"\"\"\n",
    "        #F['num_nodes'] = num_nodes\n",
    "        F['num_edges'] = num_edges\n",
    "        \n",
    "        #H = hierarchical_degree(G, nivel_max=3)\n",
    "        #F['avg_degree'] =  np.average(H[0,:])\n",
    "        #F['avg_hier2']  =  np.average(H[1,:])\n",
    "        #F['avg_hier3']  =  np.average(H[2,:])\n",
    "        ##F['avg_clust']  = nx.average_clustering(G) #0, para este caso todas as redes obtiver 0\n",
    "        ##tic()  #avgpathlenght is expensive\n",
    "        #F['avg_path']   =  nx.algorithms.average_shortest_path_length(G)\n",
    "        #F['pearson']    =  nx.algorithms.degree_pearson_correlation_coefficient(G) #-0.18656860948991077   \n",
    "        \n",
    "        #F['avg_leff']   =  nx.local_efficiency(G) \n",
    "        #F['avg_geff']   =  nx.global_efficiency(G)\n",
    "        #F['avg_trans']  =  nx.algorithms.transitivity(G) #0\n",
    "\n",
    "        \"\"\" Local measures \"\"\"\n",
    "        #ecc  =   nx.algorithms.eccentricity(G)          # [0.01408451 0.   0.32394366 0.   0.66197183]\n",
    "        #tic() #betweeness is expensive\n",
    "        #bet  =   nx.algorithms.betweenness_centrality(G)# [0.97183099 0.   0.   0.01408451 0.01408451]\n",
    "        #katz =   nx.algorithms.katz_centrality(G)       # [0.67605634 0.29577465 0.    0.  0.02816901]\n",
    "        #clust  = nx.algorithms.clustering(G)           #[0. 0. 1. 0. 0.] O CLUSTERING NESTAS REDES DA O\n",
    "        #sqclust= nx.algorithms.square_clustering(G)    #[0.64788732 0.04225352 0.02816901 0.01408451 0.26760563]\n",
    "        #close  = nx.algorithms.closeness_centrality(G) #[0.64788732 0.32394366 0.    0.    0.02816901]  \n",
    "        #degcen = nx.algorithms.degree_centrality(G)    #[0.97183099 0.   0.     0.    0.02816901]\n",
    "\n",
    "\n",
    "        #F['avg_ecc']    = np.average(list(ecc.values()))\n",
    "        #F['avg_bet']    = np.average(list(bet.values()))    \n",
    "        #F['avg_katz']   = np.average(list(katz.values()))\n",
    "        #F['avg_sqclust']= np.average(list(sqclust.values()))\n",
    "        #F['avg_close']  = np.average(list(close.values()))\n",
    "        #F['avg_degcen'] = np.average(list(degcen.values()))\n",
    "\n",
    "        return F \n",
    "\n",
    "# def histo_descriptor(array, bins):\n",
    "#     hist, bin_edges = np.histogram(array, bins = bins)\n",
    "#     return hist/sum(hist) #density_histo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model as networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reactions = pd.read_csv('UNIMIB_data/ReactionMetabolites_list/R22_reactions.txt',sep=\"\\t\")\n",
    "metabolites= pd.read_csv('UNIMIB_data/ReactionMetabolites_list/R22_metabolites.txt',sep=\"\\t\")\n",
    "\n",
    "\n",
    "def read_network(filename): \n",
    "    \"\"\" return complete gcc network\"\"\"\n",
    "    df = pd.read_csv(filename,sep=\"\\t\")\n",
    "    nodeA= df.iloc[:,0]\n",
    "    nodeB= df.iloc[:,1]\n",
    "    peso = df.iloc[:,2]\n",
    "\n",
    "    all_nodes =pd.concat([nodeA, nodeB], ignore_index =True) #ignore_index, i.e re-indexa\n",
    "\n",
    "    G=nx.Graph() \n",
    "\n",
    "    #add nodes\n",
    "    for m in all_nodes[all_nodes.isin(metabolites['ID'])]:\n",
    "        #G.add_node(m, color='r') #metabolite    \n",
    "        G.add_node(m) #metabolite    \n",
    "    for r in all_nodes[~all_nodes.isin(metabolites['ID'])]:\n",
    "        #G.add_node(r, color='b') #reaction\n",
    "        G.add_node(r) #reaction\n",
    "    #add edges\n",
    "    for i in range(nodeA.size):\n",
    "        e1, e2, p=nodeA.get(i), nodeB.get(i), peso.get(i)\n",
    "        G.add_edge(e1, e2, peso=float(p))   \n",
    "    return G    \n",
    "    # largest connected component\n",
    "    #G0 = sorted(nx.connected_component_subgraphs(G), key=len, reverse=True)[0]#0 = the largest network\n",
    "    #return G0\n",
    "     \n",
    "    \n",
    "def threshold_network_bigger_than(G, thre):\n",
    "    \"\"\" filtering by threshold \"\"\"\n",
    "    filtered=[(u,v) for (u,v,w) in G.edges(data=True) if (w['peso'] >= thre)]\n",
    "\n",
    "    if(len(list(filtered)) == 0):\n",
    "        raise Exception('filtered graph is empty')  \n",
    "    else: \n",
    "        # largest connected component\n",
    "        #Gthre = sorted(nx.connected_component_subgraphs(nx.Graph(filtered)), key=len, reverse=True)[0]\n",
    "        #deprecated in version 2.1\n",
    "        # identify largest connected component version 2.4\n",
    "        g=nx.Graph(filtered)\n",
    "        Gcc = sorted(nx.connected_components(g), key=len, reverse=True)\n",
    "        Gthre = G.subgraph(Gcc[0])\n",
    "        #print('thre= [%.4f, %.4f], nodes= %d'% (thre_min, thre_max, nx.number_of_nodes(Gthre)))\n",
    "        return Gthre        \n",
    "    #write\n",
    "    # nx.write_graphml(G0_thre, 'TCGA_A7_A0CE_thre=0.7_0.8.graphml')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8735\n"
     ]
    }
   ],
   "source": [
    "G= read_network('approaches/weigth/normal/TCGA_A7_A0CE.txt')\n",
    "# nx.write_graphml(G, 'TCGA_A7_A0CE.graphml') \n",
    "print(nx.number_of_nodes(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thre= 0.0001 , nodes= 8036\n",
      "thre= 0.0010 , nodes= 7793\n",
      "thre= 0.0100 , nodes= 7472\n",
      "thre= 0.1000 , nodes= 5875\n",
      "thre= 0.2000 , nodes= 3890\n",
      "thre= 0.3000 , nodes= 2494\n",
      "thre= 0.4000 , nodes= 1924\n",
      "thre= 0.5000 , nodes= 1065\n",
      "thre= 0.6000 , nodes= 504\n",
      "thre= 0.7000 , nodes= 335\n",
      "thre= 0.8000 , nodes= 242\n",
      "thre= 0.9000 , nodes= 211\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "G= read_network('approaches/weigth/cancer/TCGA_A7_A0CE.txt')\n",
    "thre= [10**-4, 10**-3, 10**-2, 0.1, 0.2,  0.3 ,0.4, 0.5,0.6, 0.7, 0.8, 0.9]\n",
    "for i in range(len(thre)):\n",
    "    Gthre=threshold_network_bigger_than(G, thre[i])\n",
    "    #Gthre=threshold_network_less_than(G, thre[i])\n",
    "    #nx.write_graphml(G, 'TCGA_A7_A0CE.graphml') \n",
    "    print('thre= %.4f , nodes= %d'% (thre[i], nx.number_of_nodes(Gthre)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thre= 0.0001 , nodes= 21602\n",
      "thre= 0.0010 , nodes= 20704\n",
      "thre= 0.0100 , nodes= 19670\n",
      "thre= 0.1000 , nodes= 14982\n",
      "thre= 0.2000 , nodes= 8688\n",
      "thre= 0.3000 , nodes= 5376\n",
      "thre= 0.4000 , nodes= 4039\n",
      "thre= 0.5000 , nodes= 2152\n",
      "thre= 0.6000 , nodes= 1160\n",
      "thre= 0.7000 , nodes= 779\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "G= read_network('approaches/weigth/cancer/TCGA_A7_A0CE.txt')\n",
    "thre= [10**-4, 10**-3, 10**-2, 0.1, 0.2,  0.3 ,0.4, 0.5,0.6, 0.7]\n",
    "for i in range(len(thre)):\n",
    "    Gthre=threshold_network_bigger_than(G, thre[i])\n",
    "    #Gthre=threshold_network_less_than(G, thre[i])\n",
    "    #nx.write_graphml(G, 'TCGA_A7_A0CE.graphml') \n",
    "    print('thre= %.4f , nodes= %d'% (thre[i], nx.number_of_edges(Gthre)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer\n",
      "TCGA_E2_A15K\t22128\t21051\t19019\t14386\t7675\t5196\t2556\t633\t316\t221\t\n",
      "TCGA_BH_A1F0\t22421\t22056\t20414\t15209\t10042\t4471\t2312\t1249\t497\t156\t\n",
      "TCGA_A7_A0DB\t21746\t21523\t19445\t14806\t9080\t5671\t2913\t416\t244\t92\t\n",
      "TCGA_BH_A1FU\t21320\t20964\t19247\t13677\t9215\t5594\t1753\t456\t129\t16\t\n",
      "TCGA_E9_A1RB\t21821\t21467\t19411\t14548\t10298\t7538\t2951\t1887\t838\t307\t\n",
      "TCGA_BH_A0H9\t21513\t20617\t19495\t14154\t9746\t4975\t1842\t491\t315\t116\t\n",
      "TCGA_BH_A0H5\t21942\t21753\t20789\t14752\t7924\t3278\t825\t301\t113\t40\t\n",
      "TCGA_BH_A0DV\t21273\t20999\t19221\t14727\t8300\t4093\t1215\t389\t178\t146\t\n",
      "TCGA_BH_A0DH\t21043\t20614\t19185\t13844\t8512\t5936\t3551\t960\t633\t306\t\n",
      "TCGA_BH_A1EO\t20489\t20228\t19085\t14265\t8747\t4036\t1253\t395\t241\t211\t\n",
      "TCGA_BH_A18Q\t21963\t21758\t20562\t14400\t7683\t4673\t1925\t869\t412\t260\t\n",
      "TCGA_A7_A13G\t21177\t20540\t18829\t14262\t8777\t5056\t2763\t1598\t907\t706\t\n",
      "TCGA_BH_A0DO\t21893\t21604\t20851\t15052\t8322\t4509\t1583\t219\t146\t95\t\n",
      "TCGA_A7_A0CH\t21065\t20765\t19026\t14728\t8250\t4556\t2228\t817\t422\t293\t\n",
      "TCGA_BH_A0HA\t21185\t20621\t19649\t13650\t7700\t5128\t2466\t1509\t534\t167\t\n",
      "TCGA_BH_A0E1\t21570\t21234\t19435\t13954\t8064\t5354\t2078\t681\t550\t358\t\n",
      "TCGA_BH_A0BW\t22279\t21864\t20658\t15546\t10505\t7867\t3398\t1406\t942\t395\t\n",
      "TCGA_BH_A18U\t21027\t20540\t19360\t14125\t7626\t4563\t2480\t1026\t358\t230\t\n",
      "TCGA_BH_A18V\t21092\t20721\t19386\t14223\t9460\t6336\t4392\t2040\t1045\t252\t\n",
      "TCGA_E9_A1R7\t21298\t20015\t18648\t12348\t7555\t4356\t1755\t932\t587\t444\t\n",
      "TCGA_E2_A1LH\t21016\t20797\t19109\t13072\t6778\t4646\t3287\t2348\t1564\t833\t\n",
      "TCGA_BH_A0E0\t21218\t20739\t19412\t14221\t9665\t4487\t2728\t1608\t1220\t759\t\n",
      "TCGA_BH_A1F2\t21280\t20869\t20217\t14740\t9933\t5154\t2189\t1025\t411\t228\t\n",
      "TCGA_BH_A0BV\t21544\t20288\t19357\t13289\t8926\t3208\t1322\t678\t226\t170\t\n",
      "TCGA_E2_A153\t20690\t20504\t19002\t13775\t7513\t4636\t1542\t383\t86\t49\t\n",
      "TCGA_BH_A0B7\t22670\t22448\t20567\t15949\t9212\t5396\t2473\t1015\t300\t84\t\n",
      "TCGA_BH_A1FM\t21500\t20856\t19051\t12587\t8817\t3654\t2214\t669\t437\t269\t\n",
      "TCGA_BH_A203\t21907\t21108\t20131\t15010\t11070\t6354\t2589\t1149\t408\t332\t\n",
      "TCGA_BH_A0DK\t21951\t21756\t20184\t14524\t7529\t4381\t1723\t453\t146\t60\t\n",
      "TCGA_E9_A1N4\t21895\t21509\t19122\t"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# Load network\n",
    "\n",
    "#left-threshold\n",
    "# thre= [0.0, 10**-4, 10**-3, 10**-2, 0.1, 0.2,  0.3 ,0.4, 0.5,0.6, 1.1]   \n",
    "# thre= [0.0, 0.1, 0.2,  0.3 ,0.4, 0.5,0.6, 1.1]   \n",
    "# thre= [0.0, 10**-4, 10**-3]   \n",
    "\n",
    "#bigger_than threshold\n",
    "\n",
    "thre= [10**-4, 10**-3, 10**-2, 0.1, 0.2,  0.3 ,0.4, 0.5,0.6, 0.7]\n",
    "\n",
    "pacientes= [f for f in listdir('approaches/weigth/cancer') if isfile(join('approaches/weigth/cancer', f))] \n",
    "#cancer has the same pacientes as normal\n",
    "\n",
    "path= 'approaches/weigth/'\n",
    "labels= ['cancer', 'normal']\n",
    "\n",
    "num_pacientes=len(pacientes)\n",
    "num_medidas=5 #'avg_degree', 'avg_hier2','avg_hier3','avg_path','pearson','avg_bet'\n",
    "#num_thre=(len(thre)-1) #Range threshold\n",
    "num_thre =len(thre)#>= threshold   \n",
    "num_descritores= num_thre * num_medidas\n",
    "\n",
    "features =  np.zeros((num_pacientes*2, num_descritores))\n",
    "k = list()\n",
    "str_clase=list()\n",
    "int_clase=list()\n",
    "atr_names= ['avg_degree', 'avg_hier2','avg_hier3','avg_path','pearson']*num_thre\n",
    "for c in range(len(labels)):\n",
    "    print(labels[c])\n",
    "    for p in range(num_pacientes):\n",
    "        G= read_network(path+labels[c]+'/'+ pacientes[p]) #reading \n",
    "        print('{}'.format(pacientes[p].replace('.txt','')),sep = \"\\t\", end=\"\\t\")\n",
    "        k.append(pacientes[p])\n",
    "        str_clase.append(labels[c])\n",
    "        int_clase.append(c)\n",
    "        #threshold      \n",
    "        #v=len(thre)-1 # #Range threshold\n",
    "        v= len(thre)  #>= threshold   \n",
    "        for i in range(v):\n",
    "            #Gthre=threshold_network_range(G, thre[i], thre[i+1]) # #Range threshold\n",
    "            Gthre=threshold_network_bigger_than(G, thre[i]) #>= threshold     \n",
    "            #Gthre=threshold_network_less_than(G, thre[i]) #<= threshold     \n",
    "            f=extract_measures(Gthre)  #dict \n",
    "            \n",
    "            #print(f)            \n",
    "            feats= list(f.values())\n",
    "            #atr_names= list(f.keys())\n",
    "                        \n",
    "            #features[(c*num_pacientes)+p][i*num_medidas:(i*num_medidas)+num_medidas] = feats[:]             \n",
    "            #print('%s, thre= [%.4f, %.4f], %s'% (pacientes[p].replace('.txt',''), thre[i], thre[i+1],feats[:] ))\n",
    "            \n",
    "            #printing  number of edges       \n",
    "            print(*feats, sep = \"\\t\", end=\"\\t\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.DataFrame(features, columns=f.keys())\n",
    "data = pd.DataFrame(features)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(k)\n",
    "\n",
    "atr_names= ['avg_degree', 'avg_hier2','avg_hier3','avg_path','pearson']*num_thre\n",
    "# print(atr_names)\n",
    "data = pd.DataFrame(features, columns=atr_names)\n",
    "col1 = pd.DataFrame(k,columns= ['paciente'])\n",
    "col2 = pd.DataFrame(str_clase,columns= ['name_class'])\n",
    "col3 = pd.DataFrame(int_clase,columns= ['class'])\n",
    "\n",
    "df = pd.concat([data, col1['paciente'], col2['name_class'],col3['class']], axis = 1)\n",
    "df = pd.concat([data,   col3['class'] ], axis = 1)\n",
    "\n",
    "# df\n",
    "\n",
    "#save dataframe to csv \n",
    "\n",
    "df = pd.concat([data, col1['paciente'], col2['name_class'],col3['class']], axis = 1)\n",
    "df.to_csv('Arffs/biggerthan.csv', sep='\\t', index=False)\n",
    "\n",
    "\n",
    "\n",
    "#save dataframe to arff\n",
    "import arff\n",
    "df = pd.concat([data,   col3['class'] ], axis = 1)\n",
    "arff.dump('biggerthan.arff', df.values, relation='thre=power', names=df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
